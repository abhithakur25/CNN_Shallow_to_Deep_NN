{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense , Conv2D, Dropout, Flatten\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "#we always initialize the random number generator to a constant seed #value for reproducibility of results.\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load data from the path specified by the user\n",
    "def data_loader(path_train,path_test):\n",
    "   train_list=os.listdir(path_train)  \n",
    "   '''\n",
    "   # Map class names to integer labels\n",
    "   train_class_labels = { label: index for index, label in enumerate(class_names) } \n",
    "   '''\n",
    "   # Number of classes in the dataset\n",
    "   num_classes=len(train_list)\n",
    "   \n",
    "   # Empty lists for loading training and testing data images as well as corresponding labels\n",
    "   x_train=[]\n",
    "   y_train=[]\n",
    "   x_test=[]\n",
    "   y_test=[]\n",
    "   \n",
    "   # Loading training data\n",
    "   for label,elem in enumerate(train_list):\n",
    "           \n",
    "           path1=path_train+'/'+str(elem)\n",
    "           images=os.listdir(path1)\n",
    "           for elem2 in images:\n",
    "               path2=path1+'/'+str(elem2)\n",
    "               # Read the image form the directory\n",
    "               img = cv2.imread(path2)   \n",
    "               # Append image to the train data list\n",
    "               x_train.append(img)\n",
    "               # Append class-label corresponding to the image\n",
    "               y_train.append(str(label))\n",
    "   \n",
    "           # Loading testing data\n",
    "           path1=path_test+'/'+str(elem)\n",
    "           images=os.listdir(path1)\n",
    "           for elem2 in images:\n",
    "               path2=path1+'/'+str(elem2)\n",
    "               # Read the image form the directory\n",
    "               img = cv2.imread(path2)\n",
    "               # Append image to the test data list\n",
    "               x_test.append(img)\n",
    "               # Append class-label corresponding to the image\n",
    "               y_test.append(str(label))\n",
    "           \n",
    "   # Convert lists into numpy arrays\n",
    "   x_train=np.asarray(x_train)\n",
    "   y_train=np.asarray(y_train)\n",
    "   x_test=np.asarray(x_test)\n",
    "   y_test=np.asarray(y_test)\n",
    "   return x_train,y_train,x_test,y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path_train='./Data/train'\n",
    "path_test='./Data/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 3)\n",
      "(60000,)\n",
      "(10000, 28, 28, 3)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "X_train,y_train,X_test,y_test=data_loader(path_train,path_test)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_shape = (X_train.shape[1], X_train.shape[2],X_train.shape[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# forcing the precision of the pixel values to be 32 bit\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255.\n",
    "X_test = X_test / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# one hot encode outputs using np_utils.to_categorical inbuilt function\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Splitting the trining data into training and validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define baseline model\n",
    "#The model is a simple neural network with one hidden layer with the same number of neurons as there are inputs (784)\n",
    "def baseline_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\t#We will add a Convolution layer with 32 filters of 3x3, keeping the padding as same\n",
    "\tmodel.add(Conv2D(32, (3,3), strides = (1,1), padding = 'same' , input_shape=input_shape, activation='relu'))\n",
    "\t#Flatten the feature map\n",
    "\tmodel.add(Flatten())\n",
    "\t#Adding FC Layer\n",
    "\tmodel.add(Dense(100, activation='relu'))\n",
    "\t#A softmax activation function is used on the output\n",
    "\t#to turn the outputs into probability-like values and \n",
    "\t#allow one class of the 10 to be selected as the model's output #prediction.\n",
    "\tmodel.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build the model\n",
    "model = baseline_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22505f88358>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "#The model is fit over 10 epochs with updates every 200 images. The test data is used as the validation dataset\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=2, batch_size=200, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Error: 1.92%\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
